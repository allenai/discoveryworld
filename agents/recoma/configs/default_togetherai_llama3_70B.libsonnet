{
    "type": "lite_llm",
    "model": "together_ai/meta-llama/Llama-3-70b-chat-hf",
    "max_tokens": 100,
    "temperature": 0,
    "top_p": 1,
    "use_cache": false,
    "stop": ["\n"]
}